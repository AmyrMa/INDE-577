{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985629ca",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf936b",
   "metadata": {},
   "source": [
    "Since our data has multiple features, then the gradient for our model at point p is defined as a vector of all partial derivatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb0ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_text\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4cfbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/AmyrMa/INDE-577/main/data/data.csv')\n",
    "df = df.drop(['id','Unnamed: 32'], axis = 1)\n",
    "df['diagnosis'] = np.where(df['diagnosis'] == 'M', 1, -1)\n",
    "y = np.array(df['diagnosis'])\n",
    "X = df.drop(['diagnosis'], axis = 1)\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7280d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c0a54",
   "metadata": {},
   "source": [
    "$y = \\beta + \\theta X$ \\\n",
    "this is the function for gradient descent, next we will implement the function to calculate the beta and theta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea36492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: 0.5242537914067388 Weights:  [0.63002669 0.78231461 0.03480327 0.07585951 0.85189393 0.67682128\n",
      " 0.07967443 0.6410996  0.53470117 0.79409415 0.62513032 0.68990476\n",
      " 0.47595592 0.38336673 0.81971996 0.94553131 0.52158149 0.3760673\n",
      " 0.72527265 0.13822093 0.10782304 0.69904969 0.55220947 0.31136686\n",
      " 0.24482814 0.83171952 0.59627623 0.4103345  0.73895863 0.87398559]\n"
     ]
    }
   ],
   "source": [
    "def initialize(dim):\n",
    "    b = random.random()\n",
    "    theta = np.random.rand(dim)\n",
    "    return b,theta\n",
    "b , theta = initialize(X.shape[1])\n",
    "print(\"Bias:\",b,'Weights: ',theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8285a088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.71826612,  -4.54364614, -12.53451023,  -0.93469517,\n",
       "        -1.50950021,   7.87339777,  -1.7399908 ,  -1.95832823,\n",
       "        -0.50977544,  -3.75728233])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_Y(b,theta,X_train):\n",
    "    return b + np.dot(X_train,theta)\n",
    "y_pred = predict_Y(b,theta,X_train)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65048a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.73516530066964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cost(y_train,y_pred):\n",
    "    Y_resd=y_train-y_pred\n",
    "    return np.sum(np.dot(Y_resd.T,Y_resd))/len(y_train-Y_resd)\n",
    "Y_hat=predict_Y(b,theta,X_train)\n",
    "get_cost(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ee76a",
   "metadata": {},
   "source": [
    "We can see that our cost value is really high, and we want to reduce our cost value as much as possible in order to obtain a good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7903d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After initialization -Bias:  0.5242537914067388 theta:  [0.63002669 0.78231461 0.03480327 0.07585951 0.85189393 0.67682128\n",
      " 0.07967443 0.6410996  0.53470117 0.79409415 0.62513032 0.68990476\n",
      " 0.47595592 0.38336673 0.81971996 0.94553131 0.52158149 0.3760673\n",
      " 0.72527265 0.13822093 0.10782304 0.69904969 0.55220947 0.31136686\n",
      " 0.24482814 0.83171952 0.59627623 0.4103345  0.73895863 0.87398559]\n",
      "After first update -Bias:  0.5090664444185378 theta:  [ 0.53933926  0.71358163 -0.06418048 -0.01806813  0.73076655  0.51251321\n",
      " -0.08475528  0.49085642  0.41249451  0.69775948  0.51248089  0.63857088\n",
      "  0.35959515  0.28292963  0.76423404  0.80911801  0.39802974  0.24925419\n",
      "  0.65173226  0.0382993   0.00895949  0.62758934  0.44474856  0.21246818\n",
      "  0.13939642  0.6937966   0.4509469   0.27001695  0.63796086  0.76317885]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.73516530066964"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_theta(x,y,y_hat,b_0,theta_o,learning_rate):\n",
    "    db=(np.sum(y_hat-y)*2)/len(y)\n",
    "    dw=(np.dot((y_hat-y),x)*2)/len(y)\n",
    "    b_1=b_0-learning_rate*db\n",
    "    theta_1=theta_o-learning_rate*dw\n",
    "    return b_1,theta_1\n",
    "print(\"After initialization -Bias: \",b,\"theta: \",theta)\n",
    "y_pred=predict_Y(b,theta,X_train)\n",
    "b,theta=update_theta(X_train,y_train,y_pred,b,theta,0.01)\n",
    "print(\"After first update -Bias: \",b,\"theta: \",theta)\n",
    "get_cost(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ccaa324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Estimate of b and theta :  -0.2216409758541156 [ 0.07899404 -0.01275424 -0.11121362  0.55615818  0.20599108  0.09908218\n",
      " -0.29763065 -0.19408131 -0.12656654 -0.12521267  0.32876616  0.09219651\n",
      " -0.04978364 -0.286427    0.08662362 -0.26345111 -0.10724566  0.27249545\n",
      " -0.04381254  0.07092773 -0.16231008  0.13008306 -0.07777435  0.31204546\n",
      " -0.00318821  0.27264787  0.44606429 -0.03666322  0.25570802 -0.11338018]\n"
     ]
    }
   ],
   "source": [
    "def run_gradient_descent(X, Y, alpha, num_iterations):\n",
    "    b, theta = initialize(X.shape[1])\n",
    "    iter_num = 0\n",
    "    gd_iterations_df = pd.DataFrame(columns = ['iteration','cost'])\n",
    "    result_idx = 0\n",
    "    for each_iter in range(num_iterations):\n",
    "        Y_hat = predict_Y(b,theta,X)\n",
    "        this_cost = get_cost(Y,Y_hat)\n",
    "        prev_b = b\n",
    "        prev_theta = theta\n",
    "        b,theta = update_theta(X,Y,Y_hat,prev_b,prev_theta,alpha)\n",
    "        if(iter_num%10==0):\n",
    "            gd_iterations_df.loc[result_idx]=[iter_num,this_cost]\n",
    "            result_idx = result_idx+1\n",
    "        iter_num +=1\n",
    "    print('Final Estimate of b and theta : ',b,theta)\n",
    "    return gd_iterations_df,b,theta\n",
    "gd_iterations_df,b,theta=run_gradient_descent(X_train,y_train,alpha=0.01,num_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3992ea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.493606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.570678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.174785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.769339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.585351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.490602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.438210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.407096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.387096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.373152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.362683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.354329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.347354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.341339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.336033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.331282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>160.0</td>\n",
       "      <td>0.326980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>170.0</td>\n",
       "      <td>0.323054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.319450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>190.0</td>\n",
       "      <td>0.316124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration       cost\n",
       "0         0.0  61.493606\n",
       "1        10.0   2.570678\n",
       "2        20.0   1.174785\n",
       "3        30.0   0.769339\n",
       "4        40.0   0.585351\n",
       "5        50.0   0.490602\n",
       "6        60.0   0.438210\n",
       "7        70.0   0.407096\n",
       "8        80.0   0.387096\n",
       "9        90.0   0.373152\n",
       "10      100.0   0.362683\n",
       "11      110.0   0.354329\n",
       "12      120.0   0.347354\n",
       "13      130.0   0.341339\n",
       "14      140.0   0.336033\n",
       "15      150.0   0.331282\n",
       "16      160.0   0.326980\n",
       "17      170.0   0.323054\n",
       "18      180.0   0.319450\n",
       "19      190.0   0.316124"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_iterations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ba7f4",
   "metadata": {},
   "source": [
    "We see that the cost value droped significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e29c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cost or MSE')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(gd_iterations_df['iteration'],gd_iterations_df['cost'])\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Cost or MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d0adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_Y(b,theta,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee64d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred < 0, -1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c088b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.98      0.98        99\n",
      "           1       0.96      0.98      0.97        44\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.97      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred, y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2ffdb",
   "metadata": {},
   "source": [
    "Given our response value is binary result, we have encoded it as -1 and 1. The gradient descent is mainly used for regression, so I decide to make any prediction that is less than 0 to euqal to -1, and otherwise 1. we see that the prediction accuracy is 0.98 which is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec46eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
